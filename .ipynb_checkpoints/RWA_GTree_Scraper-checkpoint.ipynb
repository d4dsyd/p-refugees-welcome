{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #The first Function RoomCountGumTreeScraper performs the scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RoomCountGumTreeScraper(x,counter):\n",
    "\n",
    "    #Import all the prerequiste libraries\n",
    "    \n",
    "    import urllib2\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    #The below librarirs are used to write the dataframe to a google sheet which \n",
    "    #will then be linked to through the open data site\n",
    "    import datetime\n",
    "\n",
    "    #Use selenium to execute the javascript and scrape the data\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(x)\n",
    "    \n",
    "    #Use BeautifulSoup to parse the webpage\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    #Search the elements where links are present\n",
    "    #In Gumetre to the left side of the page the total nunber of rooms for the searched suburub is always diplayed\n",
    "    #Have scraped the data from there\n",
    "    \n",
    "    g_data = soup.findAll('a',{'class':'srp-list-filter__item-link link link--no-underline'})\n",
    "\n",
    "    #initialise total_rooms\n",
    "    Total_rooms=[]\n",
    "    for match in g_data:\n",
    "        Total_rooms.append(match.text)\n",
    "\n",
    "\n",
    "    print type(Total_rooms)\n",
    "    df = pd.DataFrame(np.array(Total_rooms))\n",
    "    df.columns=[\"RawData\"]\n",
    "    #If you want to view the Rawdata just print the above df\n",
    "    \n",
    "    \n",
    "    #The actual number of rooms within the parenthesis is extracted\n",
    "    df['No_of_rooms']=df['RawData'].str.replace(r'[^(]*\\(|\\)[^)]*', '')\n",
    "    \n",
    "    #Extract the type of room basically exclude everything after a parenthesis is detected\n",
    "    df['Type_of_Department']=df['RawData'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "\n",
    "\n",
    "\n",
    "    Final_df=df[df['RawData'].str.contains('Bedroom',na = False)]\n",
    "\n",
    "    del Final_df['RawData']\n",
    "    Final_df[\"Capture_Time\"]=datetime.datetime.now()\n",
    "    Final_df.set_index('No_of_rooms')\n",
    "\n",
    "    #Call transfer function to transfer dataframe to Google Doc\n",
    "#     DFtoGoogleSheet(Final_df,counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #The function DFtoGoogleSheet used this to transfer to the Google Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Spreadsheet' object has no attribute 'Granville'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-123bdf1590ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mset_with_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDftobeTransferred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mDFtoGoogleSheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFinal_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-123bdf1590ac>\u001b[0m in \u001b[0;36mDFtoGoogleSheet\u001b[1;34m(DftobeTransferred, counter)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Open Sesame!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RWA_InnerWest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGranville\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RWA_InnerWest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParamatta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Spreadsheet' object has no attribute 'Granville'"
     ]
    }
   ],
   "source": [
    "def DFtoGoogleSheet(DftobeTransferred,counter):\n",
    "    import gspread\n",
    "    from oauth2client.service_account import ServiceAccountCredentials\n",
    "    from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "\n",
    "    # use creds to create a client to interact with the Google Drive API\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "    client = gspread.authorize(creds) \n",
    "    \n",
    "    #Open Sesame!\n",
    "    if (counter == 1): \n",
    "        sheet = client.open(\"RWA_InnerWest\").sheet1\n",
    "    elif (counter == 2):\n",
    "        sheet = client.open(\"RWA_InnerWest\").Paramatta\n",
    "    else:\n",
    "        sheet = client.open(\"RWA_InnerWest\").Newtown\n",
    "\n",
    "    #Write DataFrame to Sheet    \n",
    "    set_with_dataframe(sheet, DftobeTransferred)\n",
    "\n",
    "DFtoGoogleSheet(Final_df,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main function that calls the above to perform the scraping,the list of suburb urls are present in the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The suburb url in consderation is https://www.gumtree.com.au/s-flatshare-houseshare/granville-sydney/c18294l3003933?sort=rank\n",
      "the counter is  1\n",
      "<type 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Spreadsheet' object has no attribute 'Granville'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a3df81ee7ba2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"The suburb url in consderation is\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"the counter is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mRoomCountGumTreeScraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-8f1f990cc89d>\u001b[0m in \u001b[0;36mRoomCountGumTreeScraper\u001b[1;34m(x, counter)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m#Call transfer function to transfer dataframe to Google Doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mDFtoGoogleSheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFinal_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-051b03798101>\u001b[0m in \u001b[0;36mDFtoGoogleSheet\u001b[1;34m(DftobeTransferred, counter)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Open Sesame!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RWA_InnerWest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGranville\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RWA_InnerWest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParamatta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Spreadsheet' object has no attribute 'Granville'"
     ]
    }
   ],
   "source": [
    "#The main execution of the py script\n",
    "\n",
    "links_of_suburbs=(\"https://www.gumtree.com.au/s-flatshare-houseshare/granville-sydney/c18294l3003933?sort=rank\",\"https://www.gumtree.com.au/s-flatshare-houseshare/sydney/granville/k0c18294l3003435?sort=rank\",\"https://www.gumtree.com.au/s-flatshare-houseshare/sydney/newton/k0c18294l3003435?sort=rank\")\n",
    "\n",
    "counter=1\n",
    "for x in links_of_suburbs:\n",
    "    print \"The suburb url in consderation is\",x\n",
    "    print \"the counter is \",counter\n",
    "    RoomCountGumTreeScraper(x,counter)\n",
    "    counter=counter+1\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No_of_rooms Type_of_Department            Capture_Time\n",
      "11          19         1 Bedroom  2017-12-08 19:25:30.897\n",
      "12          15        2 Bedrooms  2017-12-08 19:25:30.897\n",
      "13           9        3 Bedrooms  2017-12-08 19:25:30.897\n",
      "14           4        4 Bedrooms  2017-12-08 19:25:30.897\n"
     ]
    }
   ],
   "source": [
    "# RoomCountGumTreeScraper(\"https://www.gumtree.com.au/s-flatshare-houseshare/granville-sydney/c18294l3003933?sort=rank\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "   No_of_rooms Type_of_Department            Capture_Time\n",
      "11          19         1 Bedroom  2017-12-08 20:07:30.228\n",
      "12          15        2 Bedrooms  2017-12-08 20:07:30.228\n",
      "13           9        3 Bedrooms  2017-12-08 20:07:30.228\n",
      "14           4        4 Bedrooms  2017-12-08 20:07:30.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidha\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(x)\n",
    "    \n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "g_data = soup.findAll('a',{'class':'srp-list-filter__item-link link link--no-underline'})\n",
    "\n",
    "#initialise total_rooms\n",
    "Total_rooms=[]\n",
    "\n",
    "for match in g_data:\n",
    "    Total_rooms.append(match.text)\n",
    "\n",
    "\n",
    "print type(Total_rooms)\n",
    "df = pd.DataFrame(np.array(Total_rooms))\n",
    "df.columns=[\"RawData\"]\n",
    "df['No_of_rooms']=df['RawData'].str.replace(r'[^(]*\\(|\\)[^)]*', '')\n",
    "df['Type_of_Department']=df['RawData'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "Final_df=df[df['RawData'].str.contains('Bedroom',na = False)]\n",
    "\n",
    "del Final_df['RawData']\n",
    "Final_df[\"Capture_Time\"]=datetime.datetime.now()\n",
    "Final_df.set_index('No_of_rooms')\n",
    "\n",
    "\n",
    "print Final_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
